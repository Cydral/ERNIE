### Models Directory

The `ERNIE/models/` directory contains trained model files generated by our evaluation framework. These models showcase the capabilities of our relatively compact neural network architecture:

ðŸ§  Network Architecture Overview - Total Parameters: ~115k, Structure: 2 different Transformer layers, Embedding Dimension: 64, Attention Heads: 8, Tokenization: Character-level (256 possible classes)

- **`llm_shakespeare_model_a.dat`**: 
  This model file demonstrates ERNIE's ability to memorize and reproduce text from William Shakespeare's works.

  > ðŸŽ­ "To be, or not to be, that is the question..." - ERNIE, reciting Shakespeare

  You can use this model to:
  - Reproduce famous Shakespeare quotes
  - Demonstrate the model's memorization capabilities
  
  > âš ï¸ **Note:** This initial model primarily showcases ERNIE's capacity for memorization rather than true creative generation. It essentially recites learned passages when given familiar (and exact) prompts.

```mizar
Input: " to be-that is the quest" (size: 24)

Generated text: "(...) - Act Three, Scene One
To be or not to be-that is the question:
Whether 'tis nobler in the mind to suffer
The slings and arrows of outrageous fortune,
Or to take arms against a sea of troubles
And, by opposing, end them. To die, to sleep-
No more-and by a sleep to say we end
The heartache and the thousand natural shocks
That flesh is heir to-'tis a consummation
Devoutly to be wished. To die, to sleep-
To sleep, perchance to dream. Ay, there's the rub,
For in that sleep of death what dreams may come,
When (...)"
```

  ðŸ” Sequence Length Impact:
It's worth noting that ERNIE's ability to accurately recite the learned text depends significantly on the input sequence length. For instance, in Hamlet's soliloquy, the phrase "To die, to sleep-" appears twice with different continuations. ERNIE correctly disambiguates between these occurrences due to its sufficiently large context window. This showcases how the model uses the broader context to accurately predict the next characters, demonstrating not just memorization, but also the capacity to utilize contextual information for precise text reproduction.

- **`llm_shakespeare_model_b.dat`**: 
  This advanced model represents ERNIE's attempt to generate text in the style of Shakespeare after training on his complete works.

  > ðŸ–‹ï¸ "Shall I compare thee to a winter's night?" - ERNIE, attempting Shakespeare-style generation

  You can use this model to:
  - Generate Shakespearean-style verses
  - Attempt to create new sonnets or monologues
  - Explore ERNIE's understanding of Shakespeare's writing style

```mizar
Input text:
Shall I compare thee to a winter's night?
Thy beauty warms the frost - bitten bough.
In darkness, thou art my guiding light,
A beacon of hope 'midst winter's vow.

Output text:

```

  > ðŸ”¬ While this model aims to capture Shakespeare's style, its output may vary in quality and authenticity. It represents an exciting step towards more sophisticated text generation!

ðŸ“Š Performance Metrics:
  - Model A (Memorization): Typically achieves near-perfect reproduction of learned passages.
  - Model B (Generation): Performance varies. Check the 'relevance score' in the test output for an indication of how well it captures Shakespeare's style and vocabulary.

We continue to refine these models to improve ERNIE's language understanding and generation capabilities.
